{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepLearningCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hfarruda/deeplearningtutorial/blob/master/deepLearningCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lL5hGtcKG9H",
        "colab_type": "text"
      },
      "source": [
        "#  Convolutional Neural Network (CNN)\n",
        "\n",
        "This tutorial is the second example of deep learning implementation, in which we exemplify a classification task. More specifically, we considered ten classes of colored pictures. \n",
        "\n",
        "First of all, we import the necessary libraries. Here we opt for using Keras (using TensorFlow backend)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0d7hiVRKQlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysjNmdk_LAZ7",
        "colab_type": "text"
      },
      "source": [
        "If you have a GPU, you can use the following code to allocate processing into it.  Otherwise, proceed to (*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRjNBwBaLFIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "from keras import backend as K\n",
        "\n",
        "print(K.tensorflow_backend._get_available_gpus())\n",
        "\n",
        "number_of_cpu_cores = 8\n",
        "config = tf.ConfigProto(device_count = {'GPU': 1 , 'CPU': number_of_cpu_cores}) \n",
        "session = tf.Session(config=config) \n",
        "keras.backend.set_session(session)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKxiJ1YgLJSa",
        "colab_type": "text"
      },
      "source": [
        "(*) In this example, we used the CIFAR10, which is consists of a colored dataset of images. It is available in Keras library, available onÂ [keras-datasets](https://keras.io/datasets/).\n",
        "This dataset is organized into two parts, where the first is called x_train/x_test and is comprises RGB images with dimensions of 32x32x3 . The second represents the targets, and the variables are called y_train/y_test, which are represented by arrays of category tags from 0 to 9.\n",
        "\n",
        "The following command is used to load the data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07m5qR6vLKOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_data, train_target), (test_data, test_target) = cifar10.load_data()\n",
        "\n",
        "train_target_one_hot_encoding = np_utils.to_categorical(train_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vpJ22EJtR0_",
        "colab_type": "text"
      },
      "source": [
        "In order to visualize a given figure, the following code can be executed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u34YZpzWh8rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_id = 700\n",
        "plt.imshow(test_data[image_id])\n",
        "plt.title(\"Test image: \" + str(image_id))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CGuskl-uF__",
        "colab_type": "text"
      },
      "source": [
        "In the following, we define the network topology. Note that in this case we do not employ dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-l1gBBYv0ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = train_data.shape[1::]\n",
        "filters = 128\n",
        "kernel_size = (3,3)\n",
        "pool_size = (2,2)\n",
        "\n",
        "optimizer = 'adam'\n",
        "loss = 'categorical_crossentropy'\n",
        "metrics = ['categorical_accuracy']\n",
        "activation = 'relu'\n",
        "activation_function_output = 'softmax'\n",
        "number_of_cnn_layers = 3\n",
        "number_of_ff_layers = 3\n",
        "number_of_units_output = train_target_one_hot_encoding.shape[1]\n",
        "\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(filters, kernel_size, input_shape = input_shape, \n",
        "                     activation = activation))\n",
        "\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(MaxPooling2D(pool_size = pool_size))\n",
        "\n",
        "for i in range(number_of_cnn_layers-1):\n",
        "  cnn_model.add(Conv2D(filters, kernel_size, input_shape = input_shape[0:2], \n",
        "                       activation = activation))\n",
        "  cnn_model.add(BatchNormalization())\n",
        "  cnn_model.add(MaxPooling2D(pool_size = pool_size))\n",
        "\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "#Feedforward network\n",
        "for i in range(number_of_ff_layers):\n",
        "  cnn_model.add(Dense(units = 128, activation = activation))\n",
        "  cnn_model.add(Dropout(0.3))\n",
        "\n",
        "cnn_model.add(Dense(units = number_of_units_output, \n",
        "                    activation = activation_function_output))\n",
        "\n",
        "cnn_model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpMASeDR0p37",
        "colab_type": "text"
      },
      "source": [
        "We can use the following command to see the network topology.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7-Y_g9g0pB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model.summary()\n",
        "#Saving the resultant figure as 'cnn_model.png'.\n",
        "plot_model(cnn_model, to_file='cnn_model.png', show_shapes=True, \n",
        "           show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efWlNTwTMS4B",
        "colab_type": "text"
      },
      "source": [
        "The training step is executed as follows. Because this network demands a high computational power, the variable epochs can receive a smaller number (e.g., 5)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-G8q3WiMSIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 30\n",
        "epochs = 50\n",
        "\n",
        "cnn_model.fit(train_data, train_target_one_hot_encoding, \n",
        "              batch_size = batch_size, epochs = epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zII-5moGMTfq",
        "colab_type": "text"
      },
      "source": [
        "Because there are three classes, we show the classification results through a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-TvNPFhwIgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = cnn_model.predict(test_data)\n",
        "found_target = predictions.argmax(axis=1)\n",
        "\n",
        "accuracy = accuracy_score(test_target, found_target)\n",
        "print(\"Accuracy =\", accuracy)\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "matrix = confusion_matrix(found_target,test_target)\n",
        "\n",
        "plt.title(\"Confusion matrix:\")\n",
        "plt.xticks(np.linspace(0,9,10))\n",
        "plt.yticks(np.linspace(0,9,10))\n",
        "plt.imshow(matrix)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
