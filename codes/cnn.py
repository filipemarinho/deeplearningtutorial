# -*- coding: utf-8 -*-
"""deepLearning_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/hfarruda/deeplearningtutorial/blob/master/deepLearning_CNN.ipynb

#  Convolutional Neural Network (CNN)

This example is part of the [*Deep Learning Tutorial*](https://github.com/hfarruda/deeplearningtutorial), authored by Henrique F. de Arruda, Alexandre Benatti, César Comin, and Luciano da Fontoura Costa. This code is not suitable for other data and/or applications, which will require modifications in the structure and parameters. This code has absolutely no warranty.

If you publish a paper related on this material, please cite:

H. F. de Arruda, A. Benatti, C. H. Comin, L. da F. Costa, "Learning Deep Learning (CDT-15)," 2019.

This tutorial is the second example of deep learning implementation, in which we exemplify a classification task. More specifically, we considered ten classes of color pictures. 

First of all, we import the necessary libraries. Here we opt for using Keras (using TensorFlow backend).
"""

import keras
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.layers.normalization import BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
from keras.datasets import cifar10
from keras.utils.vis_utils import plot_model
from sklearn.metrics import accuracy_score
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix

"""If you have a GPU, you can use the following code to allocate processing into it.  Otherwise, proceed to (*)."""

import tensorflow as tf 
from keras import backend as K

print(K.tensorflow_backend._get_available_gpus())

number_of_cpu_cores = 8
config = tf.ConfigProto(device_count = {'GPU': 1 , 'CPU': number_of_cpu_cores}) 
session = tf.Session(config=config) 
keras.backend.set_session(session)

"""(*) In this example, we used the CIFAR10, which is consists of a colored dataset of images. It is available in Keras library, available on [keras-datasets](https://keras.io/datasets/).
This dataset is organized into two parts, where the first is called x_train/x_test and comprises RGB images with dimensions of 32x32x3 . The second represents the targets, and the variables are called y_train/y_test, which are represented by arrays of category tags from 0 to 9.

The following command is used to load the data set.
"""

(train_data, train_target), (test_data, test_target) = cifar10.load_data()

train_target_one_hot_encoding = np_utils.to_categorical(train_target)

"""In order to visualize a given figure, the following code can be executed."""

image_id = 700
plt.imshow(test_data[image_id])
plt.title("Test image: " + str(image_id))
plt.show()

"""In the following, we define the network topology. In this case, because of the redundancy typically found in images, we do not employ dropout in the convolutional layers."""

input_shape = train_data.shape[1:]
filters = 128
kernel_size = (3,3)
pool_size = (2,2)

optimizer = 'adam'
loss = 'categorical_crossentropy'
metrics = ['categorical_accuracy']
activation = 'relu'
activation_function_output = 'softmax'
number_of_cnn_layers = 3
number_of_ff_layers = 3
number_of_units_output = train_target_one_hot_encoding.shape[1]

cnn_model = Sequential()
cnn_model.add(Conv2D(filters, kernel_size, input_shape = input_shape, 
                     activation = activation))

cnn_model.add(BatchNormalization())
cnn_model.add(MaxPooling2D(pool_size = pool_size))

for i in range(number_of_cnn_layers-1):
    cnn_model.add(Conv2D(filters, kernel_size, activation = activation))
    cnn_model.add(BatchNormalization())
    cnn_model.add(MaxPooling2D(pool_size = pool_size))

cnn_model.add(Flatten())

#Feedforward network
for i in range(number_of_ff_layers):
    cnn_model.add(Dense(units = 128, activation = activation))
    cnn_model.add(Dropout(0.3))

cnn_model.add(Dense(units = number_of_units_output, 
                    activation = activation_function_output))

cnn_model.compile(optimizer = optimizer, loss = loss, metrics = metrics)

"""We can use the following command to see the network topology."""

cnn_model.summary()
#Saving the resultant figure as 'cnn_model.png'.
plot_model(cnn_model, to_file='cnn_model.png', show_shapes=True, 
           show_layer_names=True)

"""The training step is executed as follows. Because this network demands a high computational power, we can use a small number of epochs."""

batch_size = 30
epochs = 50

cnn_model.fit(train_data, train_target_one_hot_encoding, 
              batch_size = batch_size, epochs = epochs)

"""Since there are more than two classes, we show the classification results through a confusion matrix."""

predictions = cnn_model.predict(test_data)
found_target = predictions.argmax(axis=1)

accuracy = accuracy_score(test_target, found_target)
print("Accuracy =", accuracy)

print("Confusion matrix:")
matrix = confusion_matrix(found_target,test_target)

plt.title("Confusion matrix:")
plt.xticks(np.linspace(0,9,10))
plt.yticks(np.linspace(0,9,10))
plt.imshow(matrix)
plt.show()

"""
## License

This Deep Learning Tutorial is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 (CC BY-NC-ND 4.0)International License.

## Acknowledgments
Henrique F. de Arruda acknowledges FAPESP for sponsorship (grant no. 2018/10489-0). Alexandre Benatti thanks Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) - Finance Code 001. Luciano da F. Costa thanks CNPq (grant no. 307085/2018-0) and NAP-PRP-USP for sponsorship. César H. Comin thanks FAPESP (Grant Nos. 15/18942-8 and 18/09125-4) for financial support. This work has been supported also by FAPESP grants 11/50761-2 and 2015/22308-2.
"""
